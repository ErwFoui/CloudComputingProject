{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Stream Consumption & Writing to Cassandra "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Cassandra workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--conf spark.ui.port=4040 --packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.0.0,com.datastax.spark:spark-cassandra-connector_2.11:2.0.0-M3 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, Row\n",
    "\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setAppName(\"CassandraWriter\") \\\n",
    "    .setMaster(\"local[2]\") \\\n",
    "    .set(\"spark.cassandra.connection.host\", \"127.0.0.1\")\n",
    "    \n",
    "spark = SparkContext(conf=conf)\n",
    "sqlContext=SQLContext(spark)\n",
    "\n",
    "data_path = \"../Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "import functools\n",
    "\n",
    "\n",
    "# Define helper function to concatenate streaming DataFrames\n",
    "def unionAll(df_list):\n",
    "    return functools.reduce(lambda df1,df2: df1.union(df2.select(df1.columns)), df_list)\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for year in range(1995, 2009):\n",
    "    print(year)\n",
    "    for month in range(1, 13):\n",
    "        csv_path = data_path + \"/\" + str(year) + \"/\" + str(month)\n",
    "\n",
    "#         Use of Spark static DataFrames because aggregation operations (e.g., JOINS) are not supported for streaming datasets \n",
    "        dfs.append(sqlContext.read.options(header='True', inferSchema='True', delimiter=',').csv(data_path + \"/\" + str(year) + \"/\" + str(month) + \"/\" + str(month) + \".csv\"))\n",
    "        \n",
    "df = unionAll(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"flights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) To save data to Cassandra, please run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cassandra requires a unique primary key, that we add here + column names must be in lowercase format\n",
    "# from pyspark.sql.functions import monotonically_increasing_id \n",
    "\n",
    "\n",
    "# df_index = df.toDF(*[col.lower() for col in df.columns]).withColumn(\"id\", monotonically_increasing_id())\n",
    "# df_index.createOrReplaceTempView(\"flights\")\n",
    "# df_index.write.format(\"org.apache.spark.sql.cassandra\").mode('overwrite').options(table=\"flights\", keyspace=\"task2\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 For each airport X, rank the top-10 carriers in decreasing order of on-time departure performance from X.\n",
    "Let us first populate the \"task2.flights_2_1\" table in Cassandra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+----+\n",
      "|origin|carrier|avg_delay|rank|\n",
      "+------+-------+---------+----+\n",
      "|   BGM|     DH|    1.669|   1|\n",
      "|   BGM|     OH|    2.068|   2|\n",
      "|   BGM|     US|    4.821|   3|\n",
      "|   BGM|     9E|    8.388|   4|\n",
      "|   BGM|     EV|   13.624|   5|\n",
      "|   DLG|     AS|   12.105|   1|\n",
      "|   INL|     9E|    6.169|   1|\n",
      "|   PSE|     CO|     0.97|   1|\n",
      "|   PSE|     B6|     2.03|   2|\n",
      "|   MSY|     HP|    2.373|   1|\n",
      "|   MSY|     NW|    2.514|   2|\n",
      "|   MSY|     XE|    4.222|   3|\n",
      "|   MSY|     F9|    4.464|   4|\n",
      "|   MSY|     9E|      5.2|   5|\n",
      "|   MSY|     DL|    5.427|   6|\n",
      "|   MSY|     US|    5.443|   7|\n",
      "|   MSY|     CO|    6.027|   8|\n",
      "|   MSY|     OO|     6.54|   9|\n",
      "|   MSY|     AA|    6.739|  10|\n",
      "|   GEG|     US|    2.362|   1|\n",
      "+------+-------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_2_1 = sqlContext.sql(\"SELECT * FROM(\\\n",
    "                        SELECT \\\n",
    "                        *,\\\n",
    "                        rank() OVER (PARTITION BY origin ORDER BY avg_delay, carrier) AS rank\\\n",
    "                        FROM (\\\n",
    "                        SELECT \\\n",
    "                           ORIGIN AS origin,\\\n",
    "                           OP_UNIQUE_CARRIER AS carrier,\\\n",
    "                           round(avg(DEP_DELAY), 3) AS avg_delay\\\n",
    "                        FROM flights\\\n",
    "                        WHERE CANCELLED=0 AND DEP_DELAY IS NOT NULL\\\n",
    "                        GROUP BY ORIGIN, OP_UNIQUE_CARRIER))\\\n",
    "                        WHERE rank <= 10\")\n",
    "\n",
    "table_2_1.createOrReplaceTempView(\"flights_2_1\")\n",
    "table_2_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) To save data to Cassandra, please run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# table_2_1.write.format(\"org.apache.spark.sql.cassandra\").mode('overwrite').options(table=\"flights_2_1\", keyspace=\"task2\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) To extract data from Cassandra, please run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query_2_1 = sqlContext.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"flights_2_1\", keyspace=\"task2\").load()\n",
    "# query_2_1.createOrReplaceTempView(\"flights_2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+----+\n",
      "|origin|carrier|avg_delay|rank|\n",
      "+------+-------+---------+----+\n",
      "|   CMH|     FL|    1.948|   1|\n",
      "|   CMH|     DH|    3.491|   2|\n",
      "|   CMH|     AA|     3.53|   3|\n",
      "|   CMH|     DL|    4.535|   4|\n",
      "|   CMH|     NW|    4.969|   5|\n",
      "|   CMH|     US|     5.66|   6|\n",
      "|   CMH|     YV|    7.961|   7|\n",
      "|   CMH|     TW|     8.03|   8|\n",
      "|   CMH|     9E|    8.326|   9|\n",
      "|   CMH|     WN|     8.37|  10|\n",
      "|   SRQ|     TZ|   -0.382|   1|\n",
      "|   SRQ|     XE|     1.49|   2|\n",
      "|   SRQ|     YV|    3.426|   3|\n",
      "|   SRQ|     US|    3.489|   4|\n",
      "|   SRQ|     DL|     5.31|   5|\n",
      "|   SRQ|     MQ|    5.351|   6|\n",
      "|   SRQ|     TW|    5.967|   7|\n",
      "|   SRQ|     FL|    6.061|   8|\n",
      "|   SRQ|     NW|    6.443|   9|\n",
      "|   SRQ|     CO|    9.286|  10|\n",
      "|   BOS|     TZ|    3.064|   1|\n",
      "|   BOS|     NW|    6.951|   2|\n",
      "|   BOS|     DL|    7.162|   3|\n",
      "|   BOS|     EV|    7.208|   4|\n",
      "|   BOS|     US|    7.941|   5|\n",
      "|   BOS|     XE|    8.987|   6|\n",
      "|   BOS|     AA|    9.178|   7|\n",
      "|   BOS|     UA|    9.577|   8|\n",
      "|   BOS|     B6|   10.046|   9|\n",
      "|   BOS|     FL|   10.131|  10|\n",
      "|   SEA|     OO|    2.877|   1|\n",
      "|   SEA|     YV|    5.122|   2|\n",
      "|   SEA|     US|    5.852|   3|\n",
      "|   SEA|     DL|    6.188|   4|\n",
      "|   SEA|     TZ|    6.345|   5|\n",
      "|   SEA|     NW|    7.009|   6|\n",
      "|   SEA|     CO|    7.031|   7|\n",
      "|   SEA|     HA|    7.133|   8|\n",
      "|   SEA|     EV|    7.896|   9|\n",
      "|   SEA|     AA|    7.951|  10|\n",
      "|   JFK|     UA|     5.63|   1|\n",
      "|   JFK|     CO|    7.656|   2|\n",
      "|   JFK|     XE|    8.114|   3|\n",
      "|   JFK|     DH|    8.743|   4|\n",
      "|   JFK|     NW|   11.032|   5|\n",
      "|   JFK|     B6|   11.229|   6|\n",
      "|   JFK|     TW|   11.496|   7|\n",
      "|   JFK|     DL|   11.728|   8|\n",
      "|   JFK|     US|   11.924|   9|\n",
      "|   JFK|     AA|   11.939|  10|\n",
      "+------+-------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM flights_2_1 WHERE origin IN ('SRQ', 'CMH', 'JFK', 'SEA', 'BOS')\").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 For each airport X, rank the top-10 airports in decreasing order of on-time departure performance from X.\n",
    "Let us first populate the \"task2.flights_2_2\" table in Cassandra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------+----+\n",
      "|origin|destination|avg_delay|rank|\n",
      "+------+-----------+---------+----+\n",
      "|   BGM|        IAD|    1.669|   1|\n",
      "|   BGM|        CVG|    2.026|   2|\n",
      "|   BGM|        PHL|    4.576|   3|\n",
      "|   BGM|        PIT|    4.829|   4|\n",
      "|   BGM|        JFK|    7.824|   5|\n",
      "|   BGM|        DTW|    8.388|   6|\n",
      "|   BGM|        ATL|   13.624|   7|\n",
      "|   DLG|        ANC|   11.918|   1|\n",
      "|   DLG|        AKN|   17.375|   2|\n",
      "|   DLG|        ADQ|   30.923|   3|\n",
      "|   INL|        MSP|    6.169|   1|\n",
      "|   PSE|        JFK|    0.796|   1|\n",
      "|   PSE|        EWR|     0.97|   2|\n",
      "|   PSE|        MCO|    4.038|   3|\n",
      "|   PSE|        FLL|    6.374|   4|\n",
      "|   MSY|        CAE|     -5.0|   1|\n",
      "|   MSY|        TWF|     -3.0|   2|\n",
      "|   MSY|        JAN|      0.0|   3|\n",
      "|   MSY|        CVG|    1.152|   4|\n",
      "|   MSY|        MEM|    1.713|   5|\n",
      "+------+-----------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_2_2 = sqlContext.sql(\"SELECT * FROM(\\\n",
    "                        SELECT \\\n",
    "                        *,\\\n",
    "                        rank() OVER (PARTITION BY origin ORDER BY avg_delay, destination) AS rank\\\n",
    "                        FROM (\\\n",
    "                        SELECT \\\n",
    "                           ORIGIN AS origin,\\\n",
    "                           DEST AS destination,\\\n",
    "                           round(avg(DEP_DELAY), 3) AS avg_delay\\\n",
    "                        FROM flights\\\n",
    "                        WHERE CANCELLED=0 AND DEP_DELAY IS NOT NULL\\\n",
    "                        GROUP BY ORIGIN, DEST))\\\n",
    "                        WHERE rank <= 10\")\n",
    "\n",
    "table_2_2.createOrReplaceTempView(\"flights_2_2\")\n",
    "table_2_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) To save data to Cassandra, please run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# table_2_2.write.format(\"org.apache.spark.sql.cassandra\").mode('overwrite').options(table=\"flights_2_2\", keyspace=\"task2\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) To extract data from Cassandra, please run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query_2_2 = sqlContext.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"flights_2_2\", keyspace=\"task2\").load()\n",
    "# query_2_2.createOrReplaceTempView(\"flights_2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------+----+\n",
      "|origin|destination|avg_delay|rank|\n",
      "+------+-----------+---------+----+\n",
      "|   CMH|        AUS|     -5.0|   1|\n",
      "|   CMH|        OMA|     -5.0|   2|\n",
      "|   CMH|        SYR|     -5.0|   3|\n",
      "|   CMH|        CLE|    0.526|   4|\n",
      "|   CMH|        MSN|      1.0|   5|\n",
      "|   CMH|        SLC|    3.555|   6|\n",
      "|   CMH|        CLT|    3.667|   7|\n",
      "|   CMH|        IAD|    4.158|   8|\n",
      "|   CMH|        MEM|    4.295|   9|\n",
      "|   CMH|        IAH|    4.381|  10|\n",
      "|   SRQ|        IAH|   -0.688|   1|\n",
      "|   SRQ|        TPA|    -0.56|   2|\n",
      "|   SRQ|        EYW|      0.0|   3|\n",
      "|   SRQ|        DFW|    1.858|   4|\n",
      "|   SRQ|        FLL|      2.0|   5|\n",
      "|   SRQ|        MCO|    2.066|   6|\n",
      "|   SRQ|        RSW|    2.199|   7|\n",
      "|   SRQ|        CLE|    2.462|   8|\n",
      "|   SRQ|        MDW|    2.638|   9|\n",
      "|   SRQ|        CLT|    2.915|  10|\n",
      "|   BOS|        SWF|     -5.0|   1|\n",
      "|   BOS|        ONT|     -3.0|   2|\n",
      "|   BOS|        GGG|      1.0|   3|\n",
      "|   BOS|        AUS|    1.324|   4|\n",
      "|   BOS|        LGA|    2.749|   5|\n",
      "|   BOS|        MSY|    3.763|   6|\n",
      "|   BOS|        LGB|    5.431|   7|\n",
      "|   BOS|        DCA|    5.538|   8|\n",
      "|   BOS|        MKE|    5.945|   9|\n",
      "|   BOS|        MDW|    6.003|  10|\n",
      "|   SEA|        EUG|      0.0|   1|\n",
      "|   SEA|        PIH|      1.0|   2|\n",
      "|   SEA|        PSC|    2.651|   3|\n",
      "|   SEA|        CVG|    3.571|   4|\n",
      "|   SEA|        MEM|      4.0|   5|\n",
      "|   SEA|        CLE|    4.749|   6|\n",
      "|   SEA|        PIT|     5.13|   7|\n",
      "|   SEA|        LIH|    5.381|   8|\n",
      "|   SEA|        SNA|    5.649|   9|\n",
      "|   SEA|        CLT|     5.68|  10|\n",
      "|   JFK|        SWF|    -10.5|   1|\n",
      "|   JFK|        STX|     -2.0|   2|\n",
      "|   JFK|        ABQ|      0.0|   3|\n",
      "|   JFK|        ANC|      0.0|   4|\n",
      "|   JFK|        ISP|      0.0|   5|\n",
      "|   JFK|        MYR|      0.0|   6|\n",
      "|   JFK|        BGR|     3.86|   7|\n",
      "|   JFK|        BQN|     3.95|   8|\n",
      "|   JFK|        CHS|    4.403|   9|\n",
      "|   JFK|        AGS|     4.75|  10|\n",
      "+------+-----------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM flights_2_2 WHERE origin IN ('SRQ', 'CMH', 'JFK', 'SEA', 'BOS')\").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 For each source-destination pair X-Y, rank the top-10 carriers in decreasing order of on-time arrival performance at Y from X.\n",
    "Let us first populate the \"task2.flights_2_3\" table in Cassandra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------+-------+----+\n",
      "|origin|destination|avg_delay|carrier|rank|\n",
      "+------+-----------+---------+-------+----+\n",
      "|   ADK|        AKN|   23.732|     AS|   1|\n",
      "|   ATL|        GSP|    0.082|     CO|   1|\n",
      "|   ATL|        GSP|    5.041|     OO|   2|\n",
      "|   ATL|        GSP|    6.459|     DL|   3|\n",
      "|   ATL|        GSP|    8.677|     9E|   4|\n",
      "|   ATL|        GSP|    8.793|     EV|   5|\n",
      "|   ATL|        GSP|   13.665|     OH|   6|\n",
      "|   AVP|        JFK|   49.882|     OH|   1|\n",
      "|   BDL|        SLC|   -3.759|     DL|   1|\n",
      "|   BFL|        SAN|   -3.599|     XE|   1|\n",
      "|   BOI|        SBA|    3.227|     OO|   1|\n",
      "|   BQN|        MCO|    0.256|     B6|   1|\n",
      "|   CLE|        SJU|   -0.912|     CO|   1|\n",
      "|   DSM|        EWR|   26.938|     XE|   1|\n",
      "|   EWR|        STT|    2.425|     CO|   1|\n",
      "|   FSD|        ATL|    6.559|     EV|   1|\n",
      "|   FSD|        ATL|    9.582|     OH|   2|\n",
      "|   GRR|        PIT|    2.994|     US|   1|\n",
      "|   HTS|        MCN|    122.0|     EV|   1|\n",
      "|   LAS|        LIT|    1.229|     WN|   1|\n",
      "+------+-----------+---------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_2_3 = sqlContext.sql(\"SELECT * FROM(\\\n",
    "                        SELECT \\\n",
    "                        *,\\\n",
    "                        rank() OVER (PARTITION BY origin, destination ORDER BY avg_delay, carrier) AS rank\\\n",
    "                        FROM (\\\n",
    "                        SELECT \\\n",
    "                           ORIGIN AS origin,\\\n",
    "                           DEST AS destination,\\\n",
    "                           round(avg(ARR_DELAY), 3) AS avg_delay,\\\n",
    "                           OP_UNIQUE_CARRIER AS carrier\\\n",
    "                        FROM flights\\\n",
    "                        WHERE CANCELLED=0 AND ARR_DELAY IS NOT NULL\\\n",
    "                        GROUP BY ORIGIN, DEST, OP_UNIQUE_CARRIER))\\\n",
    "                        WHERE rank <= 10\")\n",
    "\n",
    "table_2_3.createOrReplaceTempView(\"flights_2_3\")\n",
    "table_2_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) To save data to Cassandra, please run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# table_2_3.write.format(\"org.apache.spark.sql.cassandra\").mode('overwrite').options(table=\"flights_2_3\", keyspace=\"task2\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) To extract data from Cassandra, please run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query_2_3 = sqlContext.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"flights_2_3\", keyspace=\"task2\").load()\n",
    "# query_2_3.createOrReplaceTempView(\"flights_2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------+-------+----+\n",
      "|origin|destination|avg_delay|carrier|rank|\n",
      "+------+-----------+---------+-------+----+\n",
      "|   BOS|        LGA|    0.663|     US|   1|\n",
      "|   BOS|        LGA|     2.16|     DL|   2|\n",
      "|   BOS|        LGA|   12.482|     MQ|   3|\n",
      "|   BOS|        LGA|     25.6|     AA|   4|\n",
      "|   BOS|        LGA|   30.448|     OH|   5|\n",
      "|   BOS|        LGA|    133.0|     TZ|   6|\n",
      "|   LGA|        BOS|   -3.168|     US|   1|\n",
      "|   LGA|        BOS|    1.167|     DL|   2|\n",
      "|   LGA|        BOS|    9.471|     MQ|   3|\n",
      "|   LGA|        BOS|   27.985|     OH|   4|\n",
      "|   LGA|        BOS|     40.0|     AA|   5|\n",
      "|   MSP|        ATL|    5.378|     OO|   1|\n",
      "|   MSP|        ATL|    6.021|     DL|   2|\n",
      "|   MSP|        ATL|    6.398|     FL|   3|\n",
      "|   MSP|        ATL|     7.74|     NW|   4|\n",
      "|   MSP|        ATL|    8.352|     OH|   5|\n",
      "|   MSP|        ATL|   10.287|     EV|   6|\n",
      "|   OKC|        DFW|    1.359|     EV|   1|\n",
      "|   OKC|        DFW|    4.049|     AA|   2|\n",
      "|   OKC|        DFW|     4.71|     MQ|   3|\n",
      "|   OKC|        DFW|   12.835|     OO|   4|\n",
      "|   OKC|        DFW|   13.401|     DL|   5|\n",
      "|   OKC|        DFW|     47.5|     OH|   6|\n",
      "+------+-----------+---------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM flights_2_3 \\\n",
    "                WHERE (origin='LGA' AND destination='BOS') \\\n",
    "                OR (origin='BOS' AND destination='LGA')\\\n",
    "                OR (origin='OKC' AND destination='DFW')\\\n",
    "                OR (origin='MSP' AND destination='ATL')\\\n",
    "                ORDER BY origin, rank ASC\").show(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 For each source-destination pair X-Y, determine the mean arrival delay (in minutes) for a flight from X to Y.\n",
    "Let us first populate the \"task2.flights_2_4\" table in Cassandra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------+\n",
      "|origin|destination|avg_delay|\n",
      "+------+-----------+---------+\n",
      "|   PHL|        MCO|   10.728|\n",
      "|   MCI|        MKE|    2.011|\n",
      "|   GRR|        PIT|    2.994|\n",
      "|   EWR|        STT|    2.425|\n",
      "|   SMF|        BUR|    6.196|\n",
      "|   ATL|        GSP|    6.933|\n",
      "|   ORD|        PDX|   12.276|\n",
      "|   PBI|        DCA|    4.683|\n",
      "|   SNA|        PHX|    5.619|\n",
      "|   MCI|        IAH|    3.875|\n",
      "|   CLE|        SJU|   -0.912|\n",
      "|   LAS|        LIT|    1.229|\n",
      "|   LAX|        OXR|    1.123|\n",
      "|   BOI|        SBA|    3.227|\n",
      "|   ROC|        CLE|   13.145|\n",
      "|   DSM|        EWR|   26.938|\n",
      "|   ADK|        AKN|   23.732|\n",
      "|   LNK|        OMA|    131.5|\n",
      "|   MLI|        MCO|    5.942|\n",
      "|   HTS|        MCN|    122.0|\n",
      "+------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_2_4 = sqlContext.sql(\"SELECT\\\n",
    "                              ORIGIN AS origin,\\\n",
    "                              DEST AS destination,\\\n",
    "                              round(avg(ARR_DELAY), 3) AS avg_delay\\\n",
    "                           FROM flights\\\n",
    "                           WHERE CANCELLED=0\\\n",
    "                           GROUP BY ORIGIN, DEST\")\n",
    "\n",
    "table_2_4.createOrReplaceTempView(\"flights_2_4\")\n",
    "table_2_4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) To save data to Cassandra, please run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# table_2_4.write.format(\"org.apache.spark.sql.cassandra\").mode('overwrite').options(table=\"flights_2_4\", keyspace=\"task2\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) To extract data from Cassandra, please run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query_2_4 = sqlContext.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"flights_2_4\", keyspace=\"task2\").load()\n",
    "# query_2_4.createOrReplaceTempView(\"flights_2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------+\n",
      "|origin|destination|avg_delay|\n",
      "+------+-----------+---------+\n",
      "|   BOS|        LGA|    3.112|\n",
      "|   LGA|        BOS|    0.952|\n",
      "|   MSP|        ATL|     6.95|\n",
      "|   OKC|        DFW|    4.372|\n",
      "+------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM flights_2_4 \\\n",
    "                WHERE (origin='LGA' AND destination='BOS') \\\n",
    "                OR (origin='BOS' AND destination='LGA')\\\n",
    "                OR (origin='OKC' AND destination='DFW')\\\n",
    "                OR (origin='MSP' AND destination='ATL')\\\n",
    "                ORDER BY origin ASC\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
